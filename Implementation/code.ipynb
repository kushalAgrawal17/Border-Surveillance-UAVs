{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX_l2dcTZHvc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCy5Xv1LzZgO"
      },
      "source": [
        "## Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb_D3HxvP-Ff"
      },
      "source": [
        "### Hill climbing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWdj4HTlQAw7"
      },
      "outputs": [],
      "source": [
        "def hill_climbing_move(grid_size,cell_counters,pos):\n",
        "  x,y = pos\n",
        "  val = float('inf')\n",
        "  action = -1\n",
        "\n",
        "  if x>0 and cell_counters[x-1][y]>val:  # Move up\n",
        "      action = 0\n",
        "      val = cell_counters[x-1][y]\n",
        "  elif x<grid_size[0]-1 and cell_counters[x+1][y]>val:  # Move down\n",
        "      action = 1\n",
        "      val = cell_counters[x+1][y]\n",
        "  elif y>0 and cell_counters[x][y-1]>val:  # Move left\n",
        "      action = 2\n",
        "      val = cell_counters[x][y-1]\n",
        "  elif y<grid_size[1]-1 and cell_counters[x][y+1]>val:  # Move right\n",
        "      action = 3\n",
        "      val = cell_counters[x][y+1]\n",
        "  elif x>0 and y>0 and cell_counters[x-1][y-1]>val:  # Move diagonally up-left\n",
        "      action = 4\n",
        "      val = cell_counters[x-1][y-1]\n",
        "  elif x>0 and y<grid_size[1]-1 and cell_counters[x-1][y+1]>val:  # Move diagonally up-right\n",
        "      action = 5\n",
        "      val = cell_counters[x-1][y+1]\n",
        "  elif x<grid_size[0]-1 and y>0 and cell_counters[x+1][y-1]>val:  # Move diagonally down-left\n",
        "      action = 6\n",
        "      val = cell_counters[x+1][y-1]\n",
        "  elif x<grid_size[0]-1 and y<grid_size[1]-1 and cell_counters[x+1][y+1]>val:  # Move diagonally down-right\n",
        "      action = 7\n",
        "      val = cell_counters[x+1][y+1]\n",
        "\n",
        "  return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAwWwzQ0Wiw"
      },
      "source": [
        "### DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1cnTotnzfAq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from collections import deque\n",
        "\n",
        "class DQNAgent:\n",
        "    state_size = 53\n",
        "    action_size = 0\n",
        "    memory = deque(maxlen=50)  # Replay buffer\n",
        "    gamma = 0.95  # Discount factor\n",
        "    epsilon = 1.0  # Exploration-exploitation trade-off\n",
        "    epsilon_decay = 0.995\n",
        "    epsilon_min = 0.01\n",
        "    learning_rate = 0.001\n",
        "    epsilon2 = 0.3\n",
        "    model = None\n",
        "    target_model = None\n",
        "\n",
        "    def __init__(self, state_size, action_size):\n",
        "\n",
        "        # Initialize DQN agent parameters\n",
        "        self.state_size = 53\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=50)  # Replay buffer\n",
        "\n",
        "        # Build Q-network\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "        self.update_target_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(tf.keras.layers.Dense(24, activation='relu'))\n",
        "        model.add(tf.keras.layers.Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def epsilon_greedy(self, state):\n",
        "        # Epsilon-greedy action selection\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        q_values = self.model.predict(state.reshape(1, -1))\n",
        "        return np.argmax(q_values[0])\n",
        "\n",
        "    def update_target_model(self):\n",
        "      # Update the weights of the target model to match the Q-network weights\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def update_q_network(self, batch_size):\n",
        "        # Update Q-network using experience replay\n",
        "        if len(self.memory) < batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "\n",
        "        for state, action, reward, next_state in minibatch:\n",
        "            target = reward + self.gamma * np.amax(self.target_model.predict(next_state.reshape(1, -1))[0])\n",
        "\n",
        "            target_f = self.model.predict(state.reshape(1, -1))\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state.reshape(1, -1), target_f, epochs=1, verbose=0)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def remember(self, state, action, reward, next_state):\n",
        "        # Store experience in replay buffer\n",
        "        self.memory.append((state, action, reward, next_state))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqXSjQe3JyXZ"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqewWYGDJ04a"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    grid_size = []\n",
        "    cell_priorities = []\n",
        "    cell_counters = []\n",
        "    robot_positions = []\n",
        "    max_drones = []\n",
        "    curr_num_drones = 0\n",
        "    dqn = None\n",
        "\n",
        "    def __init__(self, grid_size, cell_counters, robot_positions, max_drones):\n",
        "      self.grid_size = grid_size\n",
        "      self.cell_counters = np.copy(cell_counters)\n",
        "      self.robot_positions = np.copy(robot_positions)\n",
        "      self.max_drones = max_drones\n",
        "      self.dqn = DQNAgent(3 + grid_size[0]*grid_size[1],8)\n",
        "\n",
        "    def feed(self,cell_priorities,cell_counters,robot_positions,curr_num_drones):\n",
        "      self.cell_priorities = cell_priorities\n",
        "      self.cell_counters = cell_counters\n",
        "      self.robot_positions = np.copy(robot_positions)\n",
        "      self.curr_num_drones = curr_num_drones\n",
        "\n",
        "    def reset(self, cell_counters, robot_positions, max_drones):\n",
        "      self.cell_counters = np.copy(cell_counters)\n",
        "      self.robot_positions = np.copy(robot_positions)\n",
        "      self.max_drones = max_drones\n",
        "      state = self.get_state()\n",
        "      return state\n",
        "\n",
        "    def step(self, robot_position , action):\n",
        "\n",
        "        x, y = robot_position\n",
        "\n",
        "        # Update the timers based on the action\n",
        "        if action == 0:  # Move up\n",
        "            x = max(0, x - 1)\n",
        "        elif action == 1:  # Move down\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "        elif action == 2:  # Move left\n",
        "            y = max(0, y - 1)\n",
        "        elif action == 3:  # Move right\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "        elif action == 4:  # Move diagonally up-left\n",
        "            x = max(0, x - 1)\n",
        "            y = max(0, y - 1)\n",
        "        elif action == 5:  # Move diagonally up-right\n",
        "            x = max(0, x - 1)\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "        elif action == 6:  # Move diagonally down-left\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "            y = max(0, y - 1)\n",
        "        elif action == 7:  # Move diagonally down-right\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "\n",
        "        reward = 0\n",
        "\n",
        "        if self.cell_counters[x][y] == 0:\n",
        "          reward = 1.0\n",
        "        elif self.cell_counters[x][y] < 0:\n",
        "          reward = self.cell_counters[x][y] / 20\n",
        "        else:\n",
        "          reward = 1.0 / (self.cell_counters[x][y] + 1)\n",
        "\n",
        "        robot_position = (x, y)\n",
        "        next_state = self.get_state(robot_position)\n",
        "        return next_state, reward\n",
        "\n",
        "    def get_state(self, robot_position):\n",
        "      state = []\n",
        "\n",
        "      x, y = robot_position\n",
        "\n",
        "      state.append(self.curr_num_drones)\n",
        "      state.append(x)\n",
        "      state.append(y)\n",
        "\n",
        "      zone_size = 10\n",
        "      num_rows = int(self.grid_size[0]/zone_size)\n",
        "      num_cols = int(self.grid_size[1]/zone_size)\n",
        "      for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            lateness = 0\n",
        "            for x in range(i * zone_size , (i + 1) * zone_size):\n",
        "              for y in range(j * zone_size , (j + 1) * zone_size):\n",
        "                if self.cell_counters[x][y] < 0:\n",
        "                  lateness += abs(self.cell_counters[x][y])\n",
        "            state.append(lateness)\n",
        "\n",
        "\n",
        "      return state\n",
        "\n",
        "    def train(self, update_target_flag , robot_positions):\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        total_reward = 0\n",
        "        for pos in robot_positions:\n",
        "            state = self.get_state(pos)\n",
        "            state = np.asarray(state).astype(np.float32)\n",
        "            action = self.dqn.epsilon_greedy(state)\n",
        "            actions.append(action)\n",
        "\n",
        "            next_state, reward = self.step(pos, action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            rewards.append(reward)\n",
        "\n",
        "            next_state = np.asarray(next_state).astype(np.float32)\n",
        "\n",
        "            self.dqn.remember(state, action, reward, next_state)\n",
        "\n",
        "        self.dqn.update_q_network(batch_size=32)\n",
        "\n",
        "        # Periodically update the target model weights\n",
        "        if update_target_flag == True:\n",
        "            self.dqn.update_target_model()\n",
        "\n",
        "        # global store_rewards\n",
        "\n",
        "        # store_rewards.append(total_reward)\n",
        "        print(f\" Total Reward: {total_reward}\")\n",
        "        return actions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKqswEpjjUv0"
      },
      "source": [
        "## Drone class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avmUVV3ajYZL"
      },
      "outputs": [],
      "source": [
        "class Drone:\n",
        "    drone_id = 0\n",
        "    current_pos = None\n",
        "    cell_counters = []\n",
        "    last_comm_time = 0\n",
        "    neighbours = []\n",
        "    battery_left = 0\n",
        "    min_battery_threshold = 0\n",
        "    grid_size = []\n",
        "    non_directed_action_probability = 0.1\n",
        "\n",
        "    def __init__(self, drone_id, pos, last_comm_time, cell_counters, battery_left, min_battery_threshold, grid_size):\n",
        "        self.drone_id = drone_id\n",
        "        self.current_pos = pos\n",
        "        self.last_comm_time = last_comm_time\n",
        "        self.cell_counters = np.copy(cell_counters)\n",
        "        self.battery_left = battery_left\n",
        "        self.min_battery_threshold = min_battery_threshold\n",
        "        self.grid_size = grid_size\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if isinstance(other, Drone):\n",
        "            return self.drone_id == other.drone_id\n",
        "        return False\n",
        "\n",
        "    def update_cell_priorities(self, counters):\n",
        "        for i in range(self.grid_size[0]):\n",
        "          for j in range(self.grid_size[1]):\n",
        "            self.cell_counters[i][j]-=1\n",
        "        for p in counters:\n",
        "            self.cell_counters[p[0]][p[1]] = p[2]\n",
        "\n",
        "    def drain_battery(self, amount):\n",
        "        self.battery_left -= amount\n",
        "        if self.battery_left < self.min_battery_threshold:\n",
        "            return -1\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def move(self,given_move):\n",
        "        x, y = self.current_pos\n",
        "        if given_move == 0:  # Move up\n",
        "            x = max(0, x - 1)\n",
        "        elif given_move == 1:  # Move down\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "        elif given_move == 2:  # Move left\n",
        "            y = max(0, y - 1)\n",
        "        elif given_move == 3:  # Move right\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "        elif given_move == 4:  # Move diagonally up-left\n",
        "            x = max(0, x - 1)\n",
        "            y = max(0, y - 1)\n",
        "        elif given_move == 5:  # Move diagonally up-right\n",
        "            x = max(0, x - 1)\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "        elif given_move == 6:  # Move diagonally down-left\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "            y = max(0, y - 1)\n",
        "        elif given_move == 7:  # Move diagonally down-right\n",
        "            x = min(self.grid_size[0] - 1, x + 1)\n",
        "            y = min(self.grid_size[1] - 1, y + 1)\n",
        "        self.current_pos = (x,y)\n",
        "        return (x,y)\n",
        "\n",
        "    ## Need to update this  (Calculate lateness here too for final evaluation)\n",
        "    def decide_and_move(self,algo, curr_num_drones):\n",
        "\n",
        "      state = []\n",
        "\n",
        "      x, y = self.current_pos\n",
        "\n",
        "      state.append(curr_num_drones)\n",
        "      state.append(x)\n",
        "      state.append(y)\n",
        "\n",
        "      zone_size = 10\n",
        "      num_rows = int(self.grid_size[0]/zone_size)\n",
        "      num_cols = int(self.grid_size[1]/zone_size)\n",
        "      for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            lateness = 0\n",
        "            for x in range(i * zone_size , (i + 1) * zone_size):\n",
        "              for y in range(j * zone_size , (j + 1) * zone_size):\n",
        "                if self.cell_counters[x][y] < 0:\n",
        "                  lateness += abs(self.cell_counters[x][y])\n",
        "            state.append(lateness)\n",
        "\n",
        "\n",
        "      state = np.asarray(state).astype(np.float32)\n",
        "      if np.random.rand() <= self.non_directed_action_probability:\n",
        "        res = random.randrange(8)\n",
        "      else:\n",
        "        res = algo(state)\n",
        "      return self.move(res)\n",
        "\n",
        "    def decide_and_move_hill_climb(self):\n",
        "        if np.random.rand() <= self.non_directed_action_probability:\n",
        "          res = random.randrange(8)\n",
        "        else:\n",
        "          res = hill_climbing_move(self.grid_size,self.cell_counters,self.current_pos)\n",
        "        return self.move(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW-LthU6uWoB"
      },
      "source": [
        "## Environment class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPQbBXEanqqF"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    flying_drones = []\n",
        "    grid_size = []\n",
        "\n",
        "    def reset(self):\n",
        "      self.flying_drones = []\n",
        "\n",
        "    def suspicious_locations(self):\n",
        "        max_row = self.grid_size[0]\n",
        "        max_col = self.grid_size[1]\n",
        "        mean = 0\n",
        "        std_dev = 5\n",
        "        num_samples = self.flying_drones.__len__()\n",
        "        suspicious_values = np.random.normal(mean, std_dev, num_samples)\n",
        "        return suspicious_values\n",
        "\n",
        "    def __init__(self, grid_size):\n",
        "        self.grid_size = grid_size\n",
        "\n",
        "    def add_drone(self,drone):\n",
        "        self.flying_drones.append(drone)\n",
        "\n",
        "    def drain_battery(self):\n",
        "        to_remove = []\n",
        "        for drone in self.flying_drones:\n",
        "            res = drone.drain_battery(random.uniform(1.0, 2.0))\n",
        "            if res == -1:\n",
        "              to_remove.append(drone)\n",
        "        for drone in to_remove:\n",
        "          self.flying_drones.remove(drone)\n",
        "        return to_remove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhTtNx3Oucxv"
      },
      "source": [
        "## Basestation class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jwnVtpgue0u"
      },
      "outputs": [],
      "source": [
        "class Basestation:\n",
        "  grid_size = []\n",
        "  next_drone_id = 0\n",
        "  cell_priorities = []\n",
        "  cell_counters = []\n",
        "  flying_drones = []\n",
        "  robot_movement_data = []\n",
        "  suspicion_data = []\n",
        "  pos = (0,0)\n",
        "  trainer = None\n",
        "\n",
        "  def reset(self):\n",
        "    self.next_drone_id = 0\n",
        "    for i in range(self.grid_size[0]):\n",
        "      for j in range(self.grid_size[1]):\n",
        "        self.cell_counters[i][j] = self.cell_priorities[i][j]\n",
        "    self.suspicion_data = []\n",
        "    self.flying_drones = []\n",
        "    self.robot_movement_data = []\n",
        "\n",
        "  def __init__(self, grid_size, max_drones):\n",
        "    self.grid_size = grid_size\n",
        "    self.cell_priorities = np.random.randint(10, 25, size=(grid_size[0], grid_size[1]))  # Random initial timers\n",
        "    self.cell_counters = np.copy(self.cell_priorities)\n",
        "    self.trainer = Trainer(grid_size,self.cell_priorities,self.robot_movement_data,max_drones)\n",
        "\n",
        "  def receive_data(self,robot_movement_data, suspicion_data):\n",
        "    self.robot_movement_data = np.copy(robot_movement_data)\n",
        "    self.suspicion_data = suspicion_data\n",
        "    total_lateness = 0\n",
        "    for x,y in robot_movement_data:\n",
        "      if self.cell_counters[x][y] < 0:\n",
        "        total_lateness += abs(self.cell_counters[x][y])\n",
        "    return total_lateness\n",
        "\n",
        "  def fly_new_drone(self,curr_time):\n",
        "    drone = Drone(drone_id=self.next_drone_id,\n",
        "                  pos = self.pos,\n",
        "                  last_comm_time=curr_time,\n",
        "                  cell_counters=self.cell_counters,\n",
        "                  battery_left=random.randint(30, 50),\n",
        "                  min_battery_threshold=10,\n",
        "                  grid_size=self.grid_size)\n",
        "    self.flying_drones.append(drone)\n",
        "    arrayTemp = np.array([self.pos], dtype=tuple)\n",
        "    if self.next_drone_id==0:\n",
        "      self.robot_movement_data  = np.array([self.pos], dtype=tuple)\n",
        "    else:\n",
        "      self.robot_movement_data = np.concatenate((self.robot_movement_data, arrayTemp),axis=0)\n",
        "    self.next_drone_id+=1\n",
        "    return drone\n",
        "\n",
        "  def broadcast_and_update_prioities(self):\n",
        "    changed = []\n",
        "    for i in range(self.grid_size[0]):\n",
        "      for j in range(self.grid_size[1]):\n",
        "        self.cell_counters[i][j]-=1\n",
        "    robo = 0\n",
        "    for d in self.suspicion_data:\n",
        "      new_priority = 1 + 4 * d\n",
        "      x,y = self.flying_drones[robo].current_pos\n",
        "      self.cell_priorities[x][y] = min(new_priority,25)\n",
        "      robo+=1\n",
        "    for d in self.robot_movement_data:\n",
        "      self.cell_counters[d[0]][d[1]] = self.cell_priorities[d[0]][d[1]]\n",
        "      changed.append([d[0],d[1],self.cell_priorities[d[0]][d[1]]])\n",
        "    return changed\n",
        "\n",
        "  def operate_trainer(self,clock):\n",
        "    self.trainer.feed(self.cell_priorities,self.cell_counters,self.robot_movement_data,self.flying_drones.__len__())\n",
        "    return self.trainer.train(clock%10,self.robot_movement_data)\n",
        "\n",
        "  def end_simulation(self,robot_movement_data, suspicion_data):\n",
        "    total_lateness = self.receive_data(robot_movement_data, suspicion_data)\n",
        "    self.broadcast_and_update_prioities()\n",
        "    for x in range(self.grid_size[0]):\n",
        "      for y in range(self.grid_size[1]):\n",
        "        if self.cell_counters[x][y] < 0:\n",
        "          total_lateness += abs(self.cell_counters[x][y])\n",
        "    return total_lateness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kUKM6FfqLSO"
      },
      "source": [
        "## Simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBvBVh1gtwjO"
      },
      "outputs": [],
      "source": [
        "class Simulator:\n",
        "  clock = 0\n",
        "  simulation_time = 100\n",
        "  warmup_time = 0\n",
        "  max_drones = 0\n",
        "  grid_size = []\n",
        "  flying_drones = []\n",
        "  to_broadcast = []\n",
        "  robot_movement_data = []\n",
        "  suspicion_data = []\n",
        "  new_drones = []\n",
        "  environment = None\n",
        "  basestation = None\n",
        "  drone_movement_algo = None\n",
        "  is_training = False\n",
        "  predicted_moves_trainer = []\n",
        "\n",
        "  total_lateness = 0\n",
        "\n",
        "  def __init__(self,simulation_time,warmup_time,max_drones,grid_size):\n",
        "    self.simulation_time = simulation_time\n",
        "    self.warmup_time = warmup_time\n",
        "    self.max_drones = max_drones\n",
        "    self.grid_size = grid_size\n",
        "    self.environment = Environment(grid_size)\n",
        "    self.basestation = Basestation(grid_size,max_drones)\n",
        "\n",
        "  def operate_basestation(self):\n",
        "    self.total_lateness += self.basestation.receive_data(self.robot_movement_data, self.suspicion_data)\n",
        "    self.to_broadcast = self.basestation.broadcast_and_update_prioities()\n",
        "    if(self.flying_drones.__len__()<self.max_drones):\n",
        "      self.new_drones.append(self.basestation.fly_new_drone(self.clock))\n",
        "    self.flying_drones += self.new_drones\n",
        "    if self.is_training:\n",
        "      self.predicted_moves_trainer = self.basestation.operate_trainer(self.clock)\n",
        "\n",
        "  def operate_drones(self):\n",
        "    for drone in self.flying_drones:\n",
        "      drone.update_cell_priorities(self.to_broadcast)\n",
        "    if self.is_training:\n",
        "      for i in range(self.flying_drones.__len__()):\n",
        "        movement = self.flying_drones[i].move(self.predicted_moves_trainer[i])\n",
        "        if movement!=None:\n",
        "          self.robot_movement_data.append(movement)\n",
        "    else:\n",
        "      for drone in self.flying_drones:\n",
        "        movement = drone.decide_and_move(self.drone_movement_algo, len(self.flying_drones))\n",
        "        # movement = drone.decide_and_move_hill_climb()\n",
        "        if movement!=None:\n",
        "          self.robot_movement_data.append(movement)\n",
        "\n",
        "  def operate_environment(self):\n",
        "    robots_to_remove = self.environment.drain_battery()\n",
        "    self.environment.flying_drones += self.new_drones\n",
        "    for drone in self.flying_drones:\n",
        "      if drone in robots_to_remove:\n",
        "        self.flying_drones.remove(drone)\n",
        "        self.basestation.flying_drones.remove(drone)\n",
        "    self.suspicion_data = self.environment.suspicious_locations()\n",
        "\n",
        "  def run_simulation(self):\n",
        "    if self.warmup_time!=0:\n",
        "      self.is_training = True\n",
        "    while self.clock < self.warmup_time:\n",
        "      if self.clock%30==0:\n",
        "        gc.collect()\n",
        "      self.operate_basestation()\n",
        "      self.robot_movement_data = []\n",
        "      self.suspicion_data = []\n",
        "      self.operate_drones()\n",
        "      self.operate_environment()\n",
        "      self.new_drones = []\n",
        "      self.clock+=1\n",
        "\n",
        "    self.drone_movement_algo = self.basestation.trainer.dqn.epsilon_greedy\n",
        "    self.is_training = False\n",
        "    self.total_lateness = 0\n",
        "    self.flying_drones = []\n",
        "    self.to_broadcast = []\n",
        "    self.robot_movement_data = []\n",
        "    self.suspicion_data = []\n",
        "    self.new_drones = []\n",
        "    self.predicted_moves_trainer = []\n",
        "    self.environment.reset()\n",
        "    self.basestation.reset()\n",
        "    self.clock = 0\n",
        "\n",
        "    while self.clock < self.simulation_time:\n",
        "      self.operate_basestation()\n",
        "      self.robot_movement_data = []\n",
        "      self.suspicion_data = []\n",
        "      self.operate_drones()\n",
        "      self.operate_environment()\n",
        "      self.clock+=1\n",
        "      self.new_drones = []\n",
        "    self.total_lateness = self.basestation.end_simulation(self.robot_movement_data, self.suspicion_data)\n",
        "\n",
        "simulator = Simulator(200,300,35,[100,50])\n",
        "simulator.run_simulation()\n",
        "print(f\"Total Lateness: {simulator.total_lateness}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tW-LthU6uWoB",
        "qhTtNx3Oucxv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
